# Applied LLMs Mastery 2024

![mind_map.png](https://github.com/aishwaryanr/awesome-generative-ai-resources/blob/main/img/Applied_LLMs_Mastery_2024/mind_map.png)

# About This Course

**Registrations are still open!! Register [here](https://forms.gle/353sQMRvS951jDYu7)**

Welcome to an exciting 10-week journey into the world of large language models!

LLMs are currently experiencing a substantial surge in popularity. Their significance has notably increased in diverse applications, including natural language processing, machine translation, and code and text generation. This rise in prominence is driven by a growing trend among both companies and individuals to leverage LLMs for automating a wide range of tasks. Understanding and learning about LLMs is highly valuable in light of their growing usage and transformative impact across various domains.

If you're eager to dive into this trend, you'll discover plenty of resources on the internet. But here's the catch ‚Äì many of them are all over the place, missing a step-by-step guide from basics to real-world use. This can be overwhelming, and you might feel a bit lost. 

Imagine this course as your comprehensive guide, exploring every aspect of using LLMs in real-world scenarios. It serves as the crucial link that brings everything together. Each week, we'll delve into the above topics, providing in-depth insights and hands-on experiences. This approach ensures you gain a thorough and well-rounded understanding of every facet within the topic.

We've organized the content into four key pillars ‚Äì 

- **Fundamentals**  (Week 1)
- **Tools and Techniques** (Weeks 2-5)
- **Deployment and Evaluation** (Weeks 6-9)
- **Challenges and Future trends** (Weeks 9-10)

This course caters to a diverse audience, including business leaders, professionals, computer science enthusiasts, or students looking to enhance their knowledge in LLMs. While we aim to keep mathematical foundations relatively light, we'll touch on LLM architectural basics in week 11 as bonus content for those interested in delving into LLM research. 

# Course Format

To make this course accessible to a wide audience, we've designed it as a self-paced audit course. You can register for the course here and course material will be released weekly, featuring mind maps, "ETMI5: Explain to Me in 5" sections for a quick overview, relevant resources, and comprehensive content to ensure your understanding of each topic. Additionally, we'll provide research papers and distilled summaries to keep you updated on the latest research. This page serves as your central hub for all resources.

Stay informed by registering for email notifications whenever new content is uploaded, or follow our updates on [LinkedIn](https://www.linkedin.com/in/areganti/). For any queries, feel free to contact the instructor at ***aish@levelup4all.org*** or on LinkedIn. At the end of each week, we'll address frequently asked questions. To maximize your learning experience, allocate 2-3 hours weekly for reading content and engaging in suggested hands-on experiments.

### üö® [Update] Asking Questions

It has come to our attention that many individuals are reaching out with questions about the content. To facilitate a feedback mechanism, we're experimenting with a method that allows people to crowdsource their doubts by posting comments on the linkedIn post featuring the week's content. If you have any questions, please share them as comments. We'll do our best to provide answers. Additionally, we encourage you to read through the thread before asking your question. This way, we can address a wide range of diverse questions.

# Key Takeaways

- Understanding the practical fundamentals of LLMs, including its capabilities and limitations
- Hands-on experience with end-to-end execution of LLM use cases
- Learning best practices for exploring and evaluating the usefulness of LLMs in specific scenarios
- Proficiency in integrating and comprehending new updates in LLMs, effectively fitting each piece into the larger puzzle and understanding its relevance.

# Course Outline

You can register for this course anytime during the 10 weeks to start receiving emails with downloadable content. 

Registrations are open now! Register [here](https://forms.gle/353sQMRvS951jDYu7)

### Click on the below topics to start learning!

üóìÔ∏è*Week 1 [Jan 15 2024]***: Practical Introduction to LLMs (Click on topics below)**

[[Week 1, Part 1] Applied LLM Foundations and Real World Use Cases](https://www.notion.so/Week-1-Part-1-Applied-LLM-Foundations-and-Real-World-Use-Cases-3f381d027e0041739fec6178d3f8aa18?pvs=21)

[[Week 1, Part 2] Domain and Task Adaptation Methods](https://www.notion.so/Week-1-Part-2-Domain-and-Task-Adaptation-Methods-6ad3284a96a241f3bd2318f4f502a1da?pvs=21)

üóìÔ∏è*Week 2 [Jan 22 2024]***: Prompting and Prompt Engineering (Click on topics below)**

[[Week 2] Prompting and Prompt Engineering ](https://www.notion.so/Week-2-Prompting-and-Prompt-Engineering-57cd1d024ac24819a0c44830a514c41d?pvs=21)

üóìÔ∏è*Week 3 [Jan 29 2024]***: LLM Fine-tuning (Click on topics below)**

[[Week 3] Fine Tuning LLMs](https://www.notion.so/Week-3-Fine-Tuning-LLMs-14ca00d3071f4e528a762f41547868ef?pvs=21)

üóìÔ∏è*Week 4 [Feb 5 2024]***: RAG (Retrieval-Augmented Generation) (Yet to Release)**

- Understanding the concept of RAG in LLMs
- Key components of RAG
- Advanced RAG Methods

üóìÔ∏è*Week 5 [ Feb 12 2024]***: Tools for building LLM Apps (Yet to Release)**

- Fine-tuning Tools
- RAG Tools
- Tools for observability, prompting, serving, vector search etc.

üóìÔ∏è*Week 6 [Feb 19 2024]***: Evaluation Techniques (Yet to Release)**

- Types of Evaluation
- Common Evaluation Benchmarks
- Common Metrics

üóìÔ∏è*Week 7 [Feb 26 2024]***: Building Your Own LLM Application (Yet to Release)**

- Components of LLM application
- Build your own LLM App end to end

üóìÔ∏è*Week 8 [March 4 2024]***: Advanced Features and Deployment (Yet to Release)**

- LLM lifecycle and LLMOps
- LLM Monitoring and Observability
- Deployment strategies

üóìÔ∏è*Week 9 [March 11 2024]***: Challenges with LLMs (Yet to Release)**

- Scaling Challenges
- Behavioral Challenges
- Future directions

üóìÔ∏è*Week 10 [March 18 2024]***: Emerging Research Trends  (Yet to Release)**

- Smaller and more performant models
- Multimodal models
- LLM Alignment

üóìÔ∏è*Week 11 *Bonus* [March 25 2024]***: Foundations  (Yet to Release)**

- Generative Models Foundations
- Self-Attention and Transformers
- Neural Networks for Language

# Disclaimer

This course content is developed by [Aishwarya Naresh Reganti](https://www.linkedin.com/in/areganti/). The course is offered independently, for **free** and is not affiliated with her professional responsibilities or employer. The content presented in this course is intended for educational purposes only and does not reflect the views or policies of any associated organizations.

# ‚òïüì∞¬†Announcements

- [Jan 30 2024] Week 3 content is out! Click [here](https://www.notion.so/Week-3-Fine-Tuning-LLMs-14ca00d3071f4e528a762f41547868ef?pvs=21) to view
- [Jan 23 2024] Week 2 content is out! Click [here](https://www.notion.so/Week-2-Prompting-and-Prompt-Engineering-57cd1d024ac24819a0c44830a514c41d?pvs=21) to view.
- [Jan 18 2024] Week 1, Part 2 content is out! Click [here](https://www.notion.so/Week-1-Part-2-Domain-and-Task-Adaptation-Methods-6ad3284a96a241f3bd2318f4f502a1da?pvs=21) to view.
- [Jan 15 2024] Week 1, Part 1 content is out! Click [here](https://www.notion.so/Week-1-Part-1-Applied-LLM-Foundations-and-Real-World-Use-Cases-3f381d027e0041739fec6178d3f8aa18?pvs=21) to view.
- **[Jan 12 2024] Register [here](https://forms.gle/353sQMRvS951jDYu7) to receive weekly course content and other course updates**

# üìéResources

- ICLR 2024 Research Paper Summary Cards (Click [here](https://www.notion.so/06f0d4fe46a94d62bff2ae001cfec22c?pvs=21))